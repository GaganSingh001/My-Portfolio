
##Install Packages and load the required packages

install.packages('rattle')
install.packages('rpart.plot')
install.packages('RColorBrewer')
install.package("caTools")
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(caTools)

# Read the train data into a dataframe
train_set <- read.csv(file.choose(), header = T,stringsAsFactors = F) 
train_set$readhome <- as.numeric(train_set$readhome)
train_set$job_performance <- as.double(train_set$job_performance)

#Run initial algorithm to find the order of importance/and the most important varibles in determining job performance to use in the trained model, 
#eliminating columns that are not important when predicting job performance
fit <- rpart(job_performance~., data  = train_set, method = "anova")
importance <- fit$variable.importance

#creates a readable dataframe of the most importance variables and their performance
importance <- as.data.frame(importance)

#DATA VERIFICATION AND CLEANUP OF IMPORTANT FIELDS USING REGRESSION. (I used "unknown" for black values for factor variables)
#reg_tl2 <too many levels>XXXXXXXXXXX
#reg_t13 good (reduced levels to only major levels) use instead of reg_t13
#edleve3 good factor
#edcat7 good factor
#edcat8 good factor
#isic1c good factor
#cntryid good factor
#cntryid_e good factor
#isic2c <too many levels>XXXXXXXXXX (will use isic1c instead)
#yrsqual good factor
#yrsqual_t good factor
#cnt_brth <too many factors> countries 92 (will use cnt_h instead)XXXXXXXXXXX
#cnt_h
#lng_ci good
#lng_bq good
#cnt_h good
#readhome change to as.numeric (used the mean for blank values)
#icthome good numeric (used the mean for blank values)
#icthome_wle_ca  numeric good
#osco1c numeric good

#Create the training dataframe to limit the algorithm to the most importanct variables.
train_set <- train_set[,c('job_performance','edcat7','cntryid_e','cntryid', 'edcat8', 'edlevel3', 'reg_tl3','lng_ci','lng_bq','yrsqual','yrsqual_t',
                        'isco1c','isic1c','icthome','icthome_wle_ca','readhome')]

#create a list of the most important variables to be used in the For loop
list <- c('edcat7','cntryid_e','cntryid', 'edcat8', 'edlevel3', 'reg_tl3','lng_ci','lng_bq','isic1c','icthome_wle_ca')


# Read the test data into a dataframe. The data must be in the same format as the train data.
test_set <- read.csv(file.choose(), header = T, stringsAsFactors = F)
test_set$readhome <- as.numeric(test_set$readhome)


#removes new levels from the test data that have not been trained in the trained model
for (i in list){
  x <- unique(train_set[[i]])
  test_set <- test_set[(test_set[[i]] %in% x),]
  train_set[[i]] <- as.factor(train_set[[i]])
  test_set[[i]] <- as.factor(test_set[[i]])
}


#Run the algorithm using only the most importance variables
fit2 <- randomForest(job_performance~edcat7 + cntryid_e + cntryid + edcat8 + edlevel3 + reg_tl3 + lng_ci + lng_bq + yrsqual + yrsqual_t +
                       + isco1c + isic1c + icthome + icthome_wle_ca + readhome, data  = train_set)

#Shows % variable explained - accuracy
fit2

#predict job performance on the new dataset
Prediction <- as.data.frame(predict(fit2,test_set))
Final <- cbind(test_set,Predictive_Value = Prediction)

#export to csv

write.csv(Final, file = "Final_Prediction.csv")

#################################### Testing accuracy of the model

train_set[sample(nrow(train_set)),]-> data


data$performance_class <- as.factor(data$job_performance)
sample.split(train_set$job_performance,SplitRatio = 0.65)-> mysplit
subset(train_set,mysplit==T)->train

subset(train_set,mysplit==F)->test

fit3 <- randomForest(job_performance~edcat7 + cntryid_e + cntryid + edcat8 + edlevel3 + lng_ci + lng_bq + yrsqual + yrsqual_t +
                + isco1c + isic1c + icthome + icthome_wle_ca + cnt_h + readhome, data  = train, importance = TRUE)


#Here is the accuracy of the model, which shows that variances were explained 76% of the time, which is good. It would be higher if not
#for the missing values in the original dataset, which i did my best to compensate for using the mean for numeric data types
fit3

Prediction <- predict(fit3,test)







